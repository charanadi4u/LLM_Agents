{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97567a37-b67b-4528-9b22-1cfcd326ec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import display,Markdown,Latex\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser,StrOutputParser\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
    "from langgraph.graph import END,StateGraph\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6fe445-5e1e-48e4-bc43-33b047eb3ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Environment Variables\n",
    "# os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "# os.environ[\"LANGCHAIN_PROJECT\"] = \"L3 Research Agent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fde11874-4357-4c20-8962-0ec61eb03bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Defining LLM\n",
    "local_llm = 'llama3:8b'\n",
    "llama3 = ChatOllama(model=local_llm, temperature=0)\n",
    "llama3_json = ChatOllama(model=local_llm, format='json', temperature=0)\n",
    "# api_key = os.getenv(\"GROQ-API_KEY\")\n",
    "# llama3 = ChatGroq(model=\"llama-3.1-405b-reasoning\", api_key=api_key,temperature=0.7, max_tokens=4096)\n",
    "# llama3_json = ChatGroq(model=\"llama-3.1-405b-reasoning\", api_key=api_key,temperature=0.7, max_tokens=4096,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d50d3a5-7aaf-42d6-9e79-bfbaceb12470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Home Depot announced Thursday that it is spending $18.3 billion to buy SRS Distribution, a huge building-projects supplier that counts professional roofers, landscapers and pool contractors as its ... The Home Depot reports sales and earnings decline for the first quarter of fiscal 2024, but reaffirms its guidance for the year. The company also announces a pending acquisition of SRS Distribution Inc. and a conference call to discuss its performance. The Home Depot announced the expiration of the waiting period under the HSR Act for its pending acquisition of SRS, a leading distributor of professional tools and equipment. The transaction is expected to close on or about June 18, 2024, subject to customary closing conditions. The Home Depot is the world's largest home improvement specialty retailer. At the end of fiscal year 2023, the company operated a total of 2,335 retail stores in all 50 states, the District of Columbia , Puerto Rico , the U.S. Virgin Islands , Guam , 10 Canadian provinces and Mexico . ATLANTA, Oct. 26, 2023 /PRNewswire/ -- The Home Depot today announced changes to align the organization around its largest growth opportunity - enabling its unique ecosystem to serve more pro customers and purchase opportunities. Ann-Marie Campbell was named senior executive vice president, effective Nov. 1, 2023. Home Depot is continuing to see its sales decline amid inflation concerns, and the home improvement retailer narrowed its fiscal 2023 outlook. ... The Associated Press is an independent global news organization dedicated to factual reporting. Founded in 1846, AP today remains the most trusted source of fast, accurate, unbiased news in all ... 2:03. Home Depot announced Thursday it is buying a roofing distributor in a massive $18 billion deal that signals the home-improvement retailer's intent to attract more business from contractors ... The U.S. Supreme Court on Monday declined to hear Home Depot's challenge to a $2.7 billion antitrust settlement involving Blue Cross Blue Shield. The decade-long case alleged that Blue Cross Blue ... The Home Depot will conduct a conference call today at 9 a.m. ET to discuss information included in this news release and a slide presentation that will be made available at 8:30 a.m. ET on its ... For investors, this is good news, because it means Home Depot's attractive capital allocation policy will continue. In fiscal 2021, 2022, and 2023, the company paid a total of $23.2 billion in ... The Home Depot has released new Halloween decor for 2024 that you don't want to miss, including an animated 12-foot skeleton, giant inflatables and more. But management isn't confident it will all be easy for the retailer. In its Tuesday morning Q1 2024 earnings report, Home Depot missed revenue expectations, reporting $36.42 billion versus Wall ... ATLANTA, (Aug. 23, 2023) - The Home Depot launched a New Homeowners Hub to equip the next generation of current and future first-time homeowners with valuable resources including DIY guides, product recommendations, design inspiration and more. According to a new survey conducted by The Home Depot in partnership with Morning Consult, home ownership is one of the most stressful milestones ... MIAMI-DADE COUNTY, Fla. - A registered sex offender was arrested Tuesday after Miami-Dade police say he stalked a 10-year-old girl inside a Home Depot store. The incident was reported at about ... One lucky baseball fan thought he was going to his local Home Depot for an uneventful trip to the home improvement store. Instead, he came home with an autographed paint mixer stick. San Diego ...\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Web Search Tool\n",
    "# pip install -U duckduckgo_search==5.3.0b4\n",
    "# ^ if running into 202 rate limit error\n",
    "\n",
    "wrapper = DuckDuckGoSearchAPIWrapper(max_results=15)\n",
    "web_search_tool = DuckDuckGoSearchRun(api_wrapper=wrapper)\n",
    "\n",
    "# Test Run\n",
    "resp = web_search_tool.invoke(\"home depot news\")\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5be640b-2944-4b64-925e-ecf763f1697b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm just an AI, I don't have feelings or emotions like humans do. I am functioning properly and ready to assist with your research question tasks. I don't have personal experiences or physical sensations, so I can't say how I am in the classical sense. However, I am designed to provide accurate and helpful responses to your questions, and I'm always happy to help!\n"
     ]
    }
   ],
   "source": [
    "# Generation Prompt\n",
    "\n",
    "generate_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    \n",
    "    <|begin_of_text|>\n",
    "    \n",
    "    <|start_header_id|>system<|end_header_id|> \n",
    "    \n",
    "    You are an AI assistant for Research Question Tasks, that synthesizes web search results. \n",
    "    Strictly use the following pieces of web search context to answer the question. If you don't know the answer, just say that you don't know. \n",
    "    keep the answer concise, but provide all of the details you can in the form of a research report. \n",
    "    Only make direct references to material if provided in the context.\n",
    "    \n",
    "    <|eot_id|>\n",
    "    \n",
    "    <|start_header_id|>user<|end_header_id|>\n",
    "    \n",
    "    Question: {question} \n",
    "    Web Search Context: {context} \n",
    "    Answer: \n",
    "    \n",
    "    <|eot_id|>\n",
    "    \n",
    "    <|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"question\", \"context\"],\n",
    ")\n",
    "\n",
    "# Chain\n",
    "generate_chain = generate_prompt | llama3 | StrOutputParser()\n",
    "\n",
    "# Test Run\n",
    "question = \"How are you?\"\n",
    "context = \"\"\n",
    "generation = generate_chain.invoke({\"context\": context, \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e93e334d-9436-434b-bade-7ecdbf4aaee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choice': 'generate'}\n"
     ]
    }
   ],
   "source": [
    "# Router\n",
    "\n",
    "router_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    \n",
    "    <|begin_of_text|>\n",
    "    \n",
    "    <|start_header_id|>system<|end_header_id|>\n",
    "    \n",
    "    You are an expert at routing a user question to either the generation stage or web search. \n",
    "    Use the web search for questions that require more context for a better answer, or recent events.\n",
    "    Otherwise, you can skip and go straight to the generation phase to respond.\n",
    "    You do not need to be stringent with the keywords in the question related to these topics.\n",
    "    Give a binary choice 'web_search' or 'generate' based on the question. \n",
    "    Return the JSON with a single key 'choice' with no premable or explanation. \n",
    "    \n",
    "    Question to route: {question} \n",
    "    \n",
    "    <|eot_id|>\n",
    "    \n",
    "    <|start_header_id|>assistant<|end_header_id|>\n",
    "    \n",
    "    \"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "# Chain\n",
    "question_router = router_prompt | llama3_json | JsonOutputParser()\n",
    "\n",
    "# Test Run\n",
    "question = \"What's up?\"\n",
    "print(question_router.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1844a17c-bfbe-4049-92df-f690f9339495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Transformation\n",
    "\n",
    "query_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    \n",
    "    <|begin_of_text|>\n",
    "    \n",
    "    <|start_header_id|>system<|end_header_id|> \n",
    "    \n",
    "    You are an expert at crafting web search queries for research questions.\n",
    "    More often than not, a user will ask a basic question that they wish to learn more about, however it might not be in the best format. \n",
    "    Reword their query to be the most effective web search string possible.\n",
    "    Return the JSON with a single key 'query' with no premable or explanation. \n",
    "    \n",
    "    Question to transform: {question} \n",
    "    \n",
    "    <|eot_id|>\n",
    "    \n",
    "    <|start_header_id|>assistant<|end_header_id|>\n",
    "    \n",
    "    \"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "# Chain\n",
    "query_chain = query_prompt | llama3_json | JsonOutputParser()\n",
    "\n",
    "# Test Run\n",
    "# question = \"What's happened recently with Macom?\"\n",
    "# print(query_chain.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6ce0adb-fafe-412a-a2d7-989fc22eb998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph State\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        search_query: revised question for web search\n",
    "        context: web_search result\n",
    "    \"\"\"\n",
    "    question : str\n",
    "    generation : str\n",
    "    search_query : str\n",
    "    context : str\n",
    "\n",
    "# Node - Generate\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Step: Generating Final Response\")\n",
    "    question = state[\"question\"]\n",
    "    context = state[\"context\"]\n",
    "\n",
    "    # Answer Generation\n",
    "    generation = generate_chain.invoke({\"context\": context, \"question\": question})\n",
    "    return {\"generation\": generation}\n",
    "\n",
    "# Node - Query Transformation\n",
    "\n",
    "def transform_query(state):\n",
    "    \"\"\"\n",
    "    Transform user question to web search\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Appended search query\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Step: Optimizing Query for Web Search\")\n",
    "    question = state['question']\n",
    "    gen_query = query_chain.invoke({\"question\": question})\n",
    "    search_query = gen_query[\"query\"]\n",
    "    return {\"search_query\": search_query}\n",
    "\n",
    "\n",
    "# Node - Web Search\"\n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Web search based on the question\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Appended web results to context\n",
    "    \"\"\"\n",
    "\n",
    "    search_query = state['search_query']\n",
    "    print(f'Step: Searching the Web for: \"{search_query}\"')\n",
    "    \n",
    "    # Web search tool call\n",
    "    search_result = web_search_tool.invoke(search_query)\n",
    "    return {\"context\": search_result}\n",
    "\n",
    "\n",
    "# Conditional Edge, Routing\n",
    "\n",
    "def route_question(state):\n",
    "    \"\"\"\n",
    "    route question to web search or generation.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Step: Routing Query\")\n",
    "    question = state['question']\n",
    "    output = question_router.invoke({\"question\": question})\n",
    "    if output['choice'] == \"web_search\":\n",
    "        print(\"Step: Routing Query to Web Search\")\n",
    "        return \"websearch\"\n",
    "    elif output['choice'] == 'generate':\n",
    "        print(\"Step: Routing Query to Generation\")\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e519adbb-27d0-46f5-9868-766f77b7adc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the nodes\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"websearch\", web_search)\n",
    "workflow.add_node(\"transform_query\", transform_query)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "\n",
    "# Build the edges\n",
    "workflow.set_conditional_entry_point(\n",
    "    route_question,\n",
    "    {\n",
    "        \"websearch\": \"transform_query\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"transform_query\", \"websearch\")\n",
    "workflow.add_edge(\"websearch\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "# Compile the workflow\n",
    "local_agent = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afb8ef8b-31fe-4eb4-9ae4-38208b9158fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import traceable\n",
    "\n",
    "# # Environment Variables\n",
    "os.environ['LANGCHAIN_API_KEY'] = ''\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"L3 Research Agent\"\n",
    "\n",
    "@traceable \n",
    "def run_agent(query):\n",
    "    output = local_agent.invoke({\"question\": query})\n",
    "    print(\"=======\")\n",
    "    display(Markdown(output[\"generation\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18c6d727-5b11-4a76-b941-4a1ba29e0075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: Routing Query\n",
      "Step: Routing Query to Web Search\n",
      "Step: Optimizing Query for Web Search\n",
      "Step: Searching the Web for: \"Apple Q3 earnings report\"\n",
      "Step: Generating Final Response\n",
      "=======\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Based on the provided web search context, Apple's Q3 earnings for fiscal year 2023 are:\n",
       "\n",
       "* Revenue: $81.8 billion, down 1% year over year\n",
       "* Earnings per diluted share: $1.26, up 5% year over year\n",
       "\n",
       "These results were announced on August 3, 2023, and can be found in the earnings call transcript provided by Apple Inc."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test it out!\n",
    "run_agent(\"What's are Apple's q3 earnings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b54b58e0-1824-4cc5-a36d-ef95458fd476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "examples = [\n",
    "    (\"What Apple's Q3 Earnings?\", \"Apple today announced financial results for its fiscal 2023 third quarter ended July 1, 2023. The Company posted quarterly revenue of $81.8 billion, down 1 percent year over year, and quarterly earnings per diluted share of $1.26, up 5 percent year over year.\"),\n",
    "    (\"What are new apple products?\", \"Apple is refreshing both iPad Pro models with OLED screens, bringing a major update in display quality. There will be two models with screen sizes around 11 and 13 inches, and we are expecting design updates. With the switch to OLED, Apple is cutting down on thickness, and the new iPad Pro models will be much thinner. We're also expecting them to adopt the M3 chip for faster performance, and Apple is planning to debut a new Magic Keyboard that gives the iPad Pro a more Mac-like feel and a new Apple Pencil.  With the 2024 iPad Air refresh, we're getting two models for the first time. The smaller iPad Air will have a 10.9-inch display like the current iPad Air, while the larger version will have a 12.9-inch display like the current 12.9-inch iPad Pro. The iPad Air models will be more affordable than the iPad Pro models, and won't have \\\"Pro\\\" features like ProMotion refresh rates and OLED displays. Rumors are mixed on whether the iPad Air will get the M2 or the M3 chip, but either option will be an improvement over the M1 in the current model.\"),\n",
    "]\n",
    "\n",
    "dataset_name = \"Apple - L3 Agent Testing\"\n",
    "if not client.has_dataset(dataset_name=dataset_name):\n",
    "    dataset = client.create_dataset(dataset_name=dataset_name)\n",
    "    inputs, outputs = zip(\n",
    "        *[({\"input\": input}, {\"expected\": expected}) for input, expected in examples]\n",
    "    )\n",
    "    client.create_examples(inputs=inputs, outputs=outputs, dataset_id=dataset.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "646aaf6b-0179-45d8-a0bf-0f716f1ace29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.evaluation import LangChainStringEvaluator, evaluate\n",
    "from langsmith.schemas import Example, Run\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# Search Tool Test\n",
    "def search_retrieval(root_run: Run, example: Example) -> dict:\n",
    "    \"\"\"\n",
    "    A simple evaluator that checks if the retrieved web search contains answer for the question\n",
    "    \"\"\"\n",
    "    # Get documents and answer\n",
    "    agent_run = next(run for run in root_run.child_runs if run.name == \"run_agent\")\n",
    "    LangGraph = next(run for run in agent_run.child_runs if run.name == \"LangGraph\")\n",
    "    search_run = next(run for run in LangGraph.child_runs if run.name == \"websearch\")\n",
    "    context = search_run.outputs[\"context\"]\n",
    "    question = agent_run.inputs[\"query\"]\n",
    "\n",
    "    # Data model\n",
    "    class GradeWebsearch(BaseModel):\n",
    "        \"\"\"Binary score for whether websearch contains question context.\"\"\"\n",
    "\n",
    "        binary_score: int = Field(description=\"Context contains answer to question, 1 or 0\")\n",
    "\n",
    "    # LLM with function call\n",
    "    api_key = os.getenv(\"GROQ-API_KEY\")\n",
    "    llm = ChatGroq(model=\"llama3-70b-8192\", api_key=api_key,temperature=0.7, max_tokens=2000)\n",
    "    structured_websearch_grader = llm.with_structured_output(GradeWebsearch)\n",
    "\n",
    "    # Prompt\n",
    "    system = \"\"\"You are a grader assessing whether an Web search contains the context needed to answer a user query. \\n\n",
    "        Give a binary score 1 or 0, where 1 means that the answer is in the web search results.\"\"\"\n",
    "    websearch_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", \"Web search: \\n\\n {context} \\n\\n Question: {question}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    websearch_grader = websearch_prompt | structured_websearch_grader\n",
    "    score = websearch_grader.invoke({\"context\": context, \"question\": question})\n",
    "    return {\"key\": \"websearch_verification\", \"score\": int(score.binary_score)}\n",
    "\n",
    "# Hallucination Test\n",
    "def hallucination(root_run: Run, example: Example) -> dict:\n",
    "    \"\"\"\n",
    "    A simple evaluator that checks to see the answer is grounded in the context\n",
    "    \"\"\"\n",
    "    # Get documents and answer\n",
    "    agent_run = next(run for run in root_run.child_runs if run.name == \"run_agent\")\n",
    "    LangGraph = next(run for run in agent_run.child_runs if run.name == \"LangGraph\")\n",
    "    search_run = next(run for run in LangGraph.child_runs if run.name == \"websearch\")\n",
    "    context = search_run.outputs[\"context\"]\n",
    "    generation = LangGraph.outputs[\"generation\"]\n",
    "\n",
    "    # Data model\n",
    "    class GradeHallucinations(BaseModel):\n",
    "        \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
    "\n",
    "        binary_score: int = Field(description=\"Answer is grounded in the facts, 1 or 0\")\n",
    "\n",
    "    # LLM with function call\n",
    "    api_key = os.getenv(\"GROQ-API_KEY\")\n",
    "    llm = ChatGroq(model=\"llama3-70b-8192\", api_key=api_key,temperature=0.7, max_tokens=2000)\n",
    "    structured_llm_grader = llm.with_structured_output(GradeHallucinations)\n",
    "\n",
    "    # Prompt\n",
    "    system = \"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n\n",
    "        Give a binary score 1 or 0, where 1 means that the answer is grounded in / supported by the set of facts.\"\"\"\n",
    "    hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", \"Set of facts: \\n\\n {context} \\n\\n LLM generation: {generation}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    hallucination_grader = hallucination_prompt | structured_llm_grader\n",
    "    score = hallucination_grader.invoke({\"context\": context, \"generation\": generation})\n",
    "    return {\"key\": \"answer_hallucination\", \"score\": int(score.binary_score)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84d37976-5714-4d69-a02e-1603849a2e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'websearch-test-1-8f611243' at:\n",
      "https://smith.langchain.com/o/b0942edf-d327-5af3-a8cb-6cfd8fb13d55/datasets/db0a88ba-7e1b-473f-9cdb-ca21cab4e41f/compare?selectedSessions=0e32113a-ee32-42ff-80cb-bbd8b518bcc9\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a53b94971574625988f0c8819c729fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: Routing Query\n",
      "Step: Routing Query\n",
      "Step: Routing Query to Web Search\n",
      "Step: Optimizing Query for Web Search\n",
      "Step: Routing Query to Web Search\n",
      "Step: Optimizing Query for Web Search\n",
      "Step: Searching the Web for: \"Apple Q3 earnings report\"\n",
      "Step: Generating Final Response\n",
      "Step: Searching the Web for: \"What's new from Apple? OR (Apple latest products) OR (new Apple devices)\"\n",
      "Step: Generating Final Response\n",
      "=======\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Based on the provided web search context, some of the new Apple products mentioned include:\n",
       "\n",
       "1. iPad Pro with M4 processor: This is a significant upgrade to the existing iPad Pro models, offering 4 times the performance.\n",
       "2. Apple Pencil Pro: A new version of the Apple Pencil designed for the iPad Air and iPad Pro.\n",
       "3. Magic Keyboard: A new keyboard designed for the iPad Air and iPad Pro.\n",
       "\n",
       "Additionally, there are rumors about upcoming products, including:\n",
       "\n",
       "1. Low-cost version of AirPods: Analyst Ming-Chi Kuo has reported that Apple is working on a low-cost version of AirPods, which may be released in the future.\n",
       "2. New Apple TV: There have been rumors that Apple could launch a new Apple TV in the first half of 2024.\n",
       "\n",
       "It's worth noting that these are just rumors and not officially confirmed by Apple."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Based on the provided web search context, here is a concise research report on Apple's Q3 earnings:\n",
       "\n",
       "**Fiscal 2023 Third Quarter Earnings**\n",
       "\n",
       "* Revenue: $81.8 billion (down 1% year over year)\n",
       "* Earnings per diluted share: $1.26 (up 5% year over year)\n",
       "\n",
       "**Key Takeaways**\n",
       "\n",
       "* Apple reported an all-time revenue record, despite a 1% YoY drop\n",
       "* iPhone sales missed analysts' expectations\n",
       "* Revenue fell 1.4% compared to the same quarter last year\n",
       "\n",
       "**Upcoming Earnings Report**\n",
       "\n",
       "* Apple will report its Q3 2024 earnings on Thursday, August 1\n",
       "* The report will cover the months of April, May, and June, including the launch of the new M3 chip\n",
       "\n",
       "**Past Earnings Reports**\n",
       "\n",
       "* Apple reported $90.8 billion in revenue for the March quarter (Q2 2024), down 4% year over year\n",
       "* Quarterly earnings per diluted share were $1.53\n",
       "\n",
       "Note: The provided context does not mention any specific product categories or business updates beyond the general revenue and earnings figures."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment_results = evaluate(\n",
    "    lambda inputs: run_agent(inputs[\"input\"]),\n",
    "    data=\"Apple - L3 Agent Testing\",\n",
    "    evaluators=[search_retrieval, hallucination],\n",
    "    experiment_prefix=\"websearch-test-1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e145f555-fdc8-46b8-b1e8-036459df117e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
